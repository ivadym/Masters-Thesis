\chapter{Discussion and Conclusions}

\section{Discussion}

ALK is an established therapeutic target in NSCLC and several other hematologic and solid malignancies. Since its discovery as a fusion oncogene in 1994, numerous ALK inhibitors have been introduced into clinical practice. To date, drug-based treatments such as crizotinib, ceritinib, lorlatinib, and alectinib have become standard therapies for advanced ALK-positive NSCLC. However, despite the remarkable responses seen with ALK TKIs, patients invariably relapse due to acquired resistance, which is the main concern of targeted-therapies in oncogene-addicted NSCLC. Therefore, rebiopsies after progression on TKIs are essential in the treatment decision making. Overall, the logistics of obtaining repeat tumor biopsies are complicated and in most cases not clinically feasible since many patients are unable to undergo an invasive procedure. Additionally, it requires highly specialized personnel and equipment, which is expensive and leads to delay in care. Furthermore, tissue biopsies may not provide a complete picture of tumor heterogeneity.

In this context, liquid biopsy emerges as an alternative to tissue biopsy techniques, overcoming many of the latter's drawbacks. Specifically, it provides spatial and temporal information on the heterogeneity of the tumor, is minimally invasive, and allows repeated sampling, offering evidence on treatment response and cancer progression. Moreover, it is less expensive and the sample preparation is faster. However, to asses liquid biopsy samples and achieve reliable results, highly sensitive methods are required due to the scarcity of gene alterations.

Currently, ALK mutations can be detected via liquid biopsy using next generation sequencing (NGS) methods and targeted PCR assays. Both methods are attractive for specific settings using ctDNA or exosome RNA. However, PCR and the approaches derived from it can only detect known genetic changes and the identification of several biomarkers simultaneously is limited. In contrast, NGS can identify multiple tumor specific genetic alterations, including novel mutations. This advantage is due to the use of amplicon‐based plasma NGS assays, such as the one employed in this study (Oncomine\texttrademark{} Pan-Cancer Cell-Free Assay), which provide coverage of the major targetable gene alterations. In this study, with the increase in accessibility of both technologies, NGS and digital PCR had complementary roles in treatment monitoring in metastatic cancer. Specifically, the use of dPCR allowed the confirmation of low-frequency and tumor-specific mutations detected by NGS with a greater sensitivity, providing the high accuracy essential for clinical decision making.

Regarding NGS, it generates a large amount of data that must be correctly interpreted and contrasted to achieve rigorous and reliable outcomes. Because of the lack of published guidance, the way of approaching this analysis changes according to each laboratory, whose members must carry out a thorough validation by themselves to have high confidence in the performance of the NGS results. However, this process of interpreting variants to determine whether they should be considered of clinical significance is complex and often prone to subjectivity and human error. Additionally, processing raw sequence data to detect genomic abnormalities has a direct impact on disease management and patient care. 
Therefore, an appropriate automation of this procedure will improve productivity, contribute to optimized test turnaround time, and improve the accuracy of the outcomes, decreasing the number of unnecessary dPCR confirmation runs and saving resources.

In this context, an algorithm has been developed to fully automate the process of interpreting NGS results from a study population (N$=$30) diagnosed with ALK-positive NSCLC. This maintainable infrastructure, apart from showing good performance in filtering mutations, has considerably reduced the time invested on it. In the first part of this study, an average of 15–20 minutes per sample was invested in manually analyzing the sequence results (39 samples). With the implemented pipeline, this analysis is performed in seconds. Overall, it has also been possible to improve the filtering results on this study population according to the internal filters of the Ion Reporter\texttrademark{} platform (Oncomine\texttrademark{} Variants v5.12), which managed to identify only mutations in 3 (37.5\%) out of 8 ALK-positive confirmed patients, compared to 7 (87.5 \%) using the designed algorithm. Specifically, for the patient sample ($AHT$) that did not pass the implemented filter, only 1 molecular family with 12 read was assessed.

It should be noted that to test the real effectiveness of the algorithm it would be necessary to analyze a more extensive and external data set. The reason is that the developed pipeline may correspond too closely or exactly to the particular mutations in this study, and may therefore fail to fit additional data or predict future observations reliably. Therefore, the main limitation of this study is the number of patients included. In this context, larger studies will be needed to validate the findings from this thesis. Nonetheless, this study adds to the evidence that NGS, the developed algorithm, and dPCR have high concordance and accuracy in detecting ALK resistance mutations in lung cancer patients.

Regarding the clinical findings, the average number of mutation per patient was 1.7. Within the spectrum of ALK variants, it should be pointed out that most of them (87.5 \%) were identified jointly with TP53 concurrent alterations. The role of TP53 co-mutations in ALK-rearranged NSCLC is usually associated with increased degrees of genomic copy number instability and a higher somatic mutation burden \cite{NSCLC_alterations}. Therefore, co-occurring TP53 mutations predict an unfavorable outcome of therapies with TKIs, and in general of systemic therapies. On the other hand, the most prevalent mutation, G1202R, was identified in 4 different patients who had progressed on alectinib (N$=$3) and ceritinib (N$=$1). These resistances to second-generation ALK TKIs were reported to oncologists in order to switch the current treatment to another ALK inhibitor such as brigatinib or lorlatinib, which target G1202R mutations (\autoref{tab:ALK_inhibitors}). Additionally, as shown in \autoref{tab:ALK_dPCR}, the patient for whom ceritinib treatment had failed ($ARS$), previously had also developed resistance to crizotinib (G1269A mutation), which is in line with previous studies that demonstrated a progressive appearance of specific mutations for each drug \cite{ALK_resistance, ALK_inhibitors}. Finally, it is worth noting the presence of a KRAS mutation in the $JRR$ patient, which with a more detailed study could lead to future ALK and EGFR mutations being discarded, since KRAS alterations seem to exclude them \cite{Mol_bio, NSCLC_therapies}.

As it was observed through this study, treatment decision making is becoming more individualized owing to molecular testing and liquid biopsy. Furthermore, it has been proven that the detection of ALK variants using NGS, the filtering algorithm, and dPCR is useful in selecting the most optimal TKI for therapy. In this regard, the excellent agreement found between these technologies is ideal for monitoring patients. While NGS is an adequate technique for the identification of infrequent or novel molecular alterations, dPCR is responsible for making these confirmations and perform periodic tests on already diagnosed patients with a specific mutation. Additionally, the prescription of second-generation ALK inhibitors is currently performed empirically, without knowing the tumor's molecular profile at progression, which underscores even more the importance of introducing these techniques into clinical practice.

In summary, with this study it has been possible to verify the utility of massive sequencing together with the algorithm implemented for the detection and quantification of biomarkers from liquid biopsy samples in ALK-positive NSCLC patients. In this sense, these techniques have been applied in order to detect molecular markers, to identify and monitor resistance mutations, and to predict clinical outcomes.

\section{Conclusions}

\begin{enumerate}
    \item The methodology proposed in this study (liquid biopsy analysis using NGS, filtering of the sequenced data by the implemented algorithm, and confirmation of the identified alterations by dPCR) allows the detection of mutations in the ALK gene in patients with NSCLC with a detection limit of 0.1\%.
    \item ALK mutations can be assesed successfully from different types of liquid biopsies: circulating tumor DNA, exosome RNA, and cerebrospinal fluid (to study the central nervous system).
    \item The study of mutations in the ALK gene is of great clinical utility to identify resistance alterations, monitor the response to TKI treatments, and as a complement to imaging follow-ups. Furthermore, it allows predicting clinical outcomes and detecting oncogenic drivers earlier.
    \item Using custom algorithms to filter sequencing results improves the performance of data analysis services offered by NGS platform manufacturers such as Thermo Fisher and improves the efficiency and effectiveness of the entire process.
    \item NGS is a useful technology for the study of biomarkers and has an excellent concordance with dPCR in terms of genotyping.
\end{enumerate}

\section{Future Directions}

The implemented platform has been developed to be maintainable and malleable over time as new data is collected. Therefore, the modification of the filter parameters for the ALK gene, as well as the inclusion of new oncogenes (EGFR, ROS1, etc.) should be immediate.

The design of a second filter for the EGFR gene, whose mutation prevalence is even higher than that of ALK, is currently being carried out in the laboratory. Specifically, data collection has started and the first parameters have begun to be established in a procedure similar to that followed for the design of the ALK mutation filtering algorithm.

On the other hand, and in an environment with a considerable amount of data, it would be very convenient to implement a machine learning model. In this sense, the learning process and estimation of parameters could be automated as new data is incorporated.